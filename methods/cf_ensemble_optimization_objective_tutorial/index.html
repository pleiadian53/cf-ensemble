
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Semi-supervised ensemble learning with confidence weighting, optimized for imbalanced biomedical data">
      
      
        <meta name="author" content="CF-Ensemble Research Team">
      
      
        <link rel="canonical" href="https://pleiadian53.github.io/cf-ensemble/methods/cf_ensemble_optimization_objective_tutorial/">
      
      
        <link rel="prev" href="../confidence_weighting/polarity_models_tutorial/">
      
      
        <link rel="next" href="../als_mathematical_derivation/">
      
      
        
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.7.2">
    
    
      
        <title>Objective Tutorial - CF-Ensemble</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.484c7ddc.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.ab4e12ef.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#cf-ensemble-optimization-knowledge-distillation-meets-collaborative-filtering" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <div data-md-color-scheme="default" data-md-component="outdated" hidden>
        
      </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="CF-Ensemble" class="md-header__button md-logo" aria-label="CF-Ensemble" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            CF-Ensemble
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Objective Tutorial
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/pleiadian53/cf-ensemble" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    pleiadian53/cf-ensemble
  </div>
</a>
      </div>
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../.." class="md-tabs__link">
        
  
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../QUICK_REFERENCE/" class="md-tabs__link">
        
  
  
    
  
  Quick Reference

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../RESULTS_2026-01-24.md" class="md-tabs__link">
        
  
  
    
  
  Results Summary

      </a>
    </li>
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../INSTALL/" class="md-tabs__link">
          
  
  
  Getting Started

        </a>
      </li>
    
  

      
        
  
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../" class="md-tabs__link">
          
  
  
  Methods

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../failure_modes/" class="md-tabs__link">
          
  
  
  Failure Modes

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../notebooks/" class="md-tabs__link">
          
  
  
  Notebooks

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../examples_README.md" class="md-tabs__link">
          
  
  
  Examples

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../guides/" class="md-tabs__link">
          
  
  
  Setup Guides

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="CF-Ensemble" class="md-nav__button md-logo" aria-label="CF-Ensemble" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    CF-Ensemble
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/pleiadian53/cf-ensemble" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    pleiadian53/cf-ensemble
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Home
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../QUICK_REFERENCE/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Quick Reference
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../RESULTS_2026-01-24.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Results Summary
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Getting Started
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            
  
    Getting Started
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../INSTALL/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Installation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../QUICK_REFERENCE/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Quick Start
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
      
        
        
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" checked>
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    Methods
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            
  
    Methods
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../imbalanced_data_tutorial/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Imbalanced Data Tutorial
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_5_3" >
        
          
          <label class="md-nav__link" for="__nav_5_3" id="__nav_5_3_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    Confidence Weighting
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    Confidence Weighting
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../confidence_weighting/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../confidence_weighting/when_to_use_confidence_weighting/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    When to Use
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../confidence_weighting/base_classifier_quality_analysis/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Quality Analysis
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../confidence_weighting/theory_vs_empirics/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Theory vs Empirics
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../confidence_weighting/polarity_models_tutorial/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Polarity Models
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_4" checked>
        
          
          <label class="md-nav__link" for="__nav_5_4" id="__nav_5_4_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    Optimization
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_4_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_5_4">
            <span class="md-nav__icon md-icon"></span>
            
  
    Optimization
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    
  
    Objective Tutorial
  

    
  </span>
  
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    
  
    Objective Tutorial
  

    
  </span>
  
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#introduction" class="md-nav__link">
    <span class="md-ellipsis">
      
        Introduction
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#1-from-neural-networks-to-ensembles-the-structural-analogy" class="md-nav__link">
    <span class="md-ellipsis">
      
        1. From Neural Networks to Ensembles: The Structural Analogy
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="1. From Neural Networks to Ensembles: The Structural Analogy">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#knowledge-distillation-recap" class="md-nav__link">
    <span class="md-ellipsis">
      
        Knowledge Distillation Recap
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cf-ensemble-parallel" class="md-nav__link">
    <span class="md-ellipsis">
      
        CF-Ensemble Parallel
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-the-collaborative-filtering-view-of-ensemble-learning" class="md-nav__link">
    <span class="md-ellipsis">
      
        2. The Collaborative Filtering View of Ensemble Learning
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2. The Collaborative Filtering View of Ensemble Learning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#borrowing-from-recommender-systems" class="md-nav__link">
    <span class="md-ellipsis">
      
        Borrowing from Recommender Systems
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-probability-matrix" class="md-nav__link">
    <span class="md-ellipsis">
      
        The Probability Matrix
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3-matrix-factorization-finding-latent-structure" class="md-nav__link">
    <span class="md-ellipsis">
      
        3. Matrix Factorization: Finding Latent Structure
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3. Matrix Factorization: Finding Latent Structure">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#why-factorize" class="md-nav__link">
    <span class="md-ellipsis">
      
        Why Factorize?
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-factorization-model" class="md-nav__link">
    <span class="md-ellipsis">
      
        The Factorization Model
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reconstruction-via-inner-product" class="md-nav__link">
    <span class="md-ellipsis">
      
        Reconstruction via Inner Product
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4-the-reconstruction-loss-matching-the-ensemble" class="md-nav__link">
    <span class="md-ellipsis">
      
        4. The Reconstruction Loss: Matching the Ensemble
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4. The Reconstruction Loss: Matching the Ensemble">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#basic-squared-error" class="md-nav__link">
    <span class="md-ellipsis">
      
        Basic Squared Error
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#regularization" class="md-nav__link">
    <span class="md-ellipsis">
      
        Regularization
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5-confidence-weights-not-all-predictions-are-equal" class="md-nav__link">
    <span class="md-ellipsis">
      
        5. Confidence Weights: Not All Predictions Are Equal
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="5. Confidence Weights: Not All Predictions Are Equal">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-role-of-c" class="md-nav__link">
    <span class="md-ellipsis">
      
        The Role of \(C\)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#how-to-define-confidence" class="md-nav__link">
    <span class="md-ellipsis">
      
        How to Define Confidence
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#critical-insight" class="md-nav__link">
    <span class="md-ellipsis">
      
        Critical Insight
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#6-train-test-split-and-transductive-learning" class="md-nav__link">
    <span class="md-ellipsis">
      
        6. Train-Test Split and Transductive Learning
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="6. Train-Test Split and Transductive Learning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#data-partitioning" class="md-nav__link">
    <span class="md-ellipsis">
      
        Data Partitioning
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#why-this-makes-sense-for-ensemble-learning" class="md-nav__link">
    <span class="md-ellipsis">
      
        Why This Makes Sense for Ensemble Learning
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#constraints" class="md-nav__link">
    <span class="md-ellipsis">
      
        Constraints
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#7-the-supervised-loss-learning-what-signal-means" class="md-nav__link">
    <span class="md-ellipsis">
      
        7. The Supervised Loss: Learning What "Signal" Means
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="7. The Supervised Loss: Learning What &#34;Signal&#34; Means">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-aggregation-function" class="md-nav__link">
    <span class="md-ellipsis">
      
        The Aggregation Function
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#aggregation-choices" class="md-nav__link">
    <span class="md-ellipsis">
      
        Aggregation Choices
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-supervised-loss" class="md-nav__link">
    <span class="md-ellipsis">
      
        The Supervised Loss
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#8-the-complete-objective-putting-it-all-together" class="md-nav__link">
    <span class="md-ellipsis">
      
        8. The Complete Objective: Putting It All Together
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="8. The Complete Objective: Putting It All Together">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-kd-style-combined-loss" class="md-nav__link">
    <span class="md-ellipsis">
      
        The KD-Style Combined Loss
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#interpretation-of-rho" class="md-nav__link">
    <span class="md-ellipsis">
      
        Interpretation of \(\rho\)
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#9-why-this-formulation-addresses-previous-failures" class="md-nav__link">
    <span class="md-ellipsis">
      
        9. Why This Formulation Addresses Previous Failures
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="9. Why This Formulation Addresses Previous Failures">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-problem-with-pure-reconstruction" class="md-nav__link">
    <span class="md-ellipsis">
      
        The Problem with Pure Reconstruction
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#how-supervision-fixes-this" class="md-nav__link">
    <span class="md-ellipsis">
      
        How Supervision Fixes This
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-role-of-confidence-weights" class="md-nav__link">
    <span class="md-ellipsis">
      
        The Role of Confidence Weights
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#10-optimization-two-approaches" class="md-nav__link">
    <span class="md-ellipsis">
      
        10. Optimization: Two Approaches
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="10. Optimization: Two Approaches">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-challenge-non-quadratic-combined-loss" class="md-nav__link">
    <span class="md-ellipsis">
      
        The Challenge: Non-Quadratic Combined Loss
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#approach-1-als-with-label-aware-confidence-fast-approximation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Approach 1: ALS with Label-Aware Confidence (Fast Approximation)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#approach-2-joint-gradient-descent-via-pytorch-exact" class="md-nav__link">
    <span class="md-ellipsis">
      
        Approach 2: Joint Gradient Descent via PyTorch (Exact)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#which-approach-to-use" class="md-nav__link">
    <span class="md-ellipsis">
      
        Which Approach to Use?
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#11-test-time-inference" class="md-nav__link">
    <span class="md-ellipsis">
      
        11. Test-Time Inference
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="11. Test-Time Inference">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#reusing-classifier-factors" class="md-nav__link">
    <span class="md-ellipsis">
      
        Reusing Classifier Factors
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#truly-new-points-inductive-setting" class="md-nav__link">
    <span class="md-ellipsis">
      
        Truly New Points (Inductive Setting)
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#12-connection-to-other-ensemble-methods" class="md-nav__link">
    <span class="md-ellipsis">
      
        12. Connection to Other Ensemble Methods
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="12. Connection to Other Ensemble Methods">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#vs-simple-averaging" class="md-nav__link">
    <span class="md-ellipsis">
      
        vs. Simple Averaging
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vs-weighted-averaging" class="md-nav__link">
    <span class="md-ellipsis">
      
        vs. Weighted Averaging
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vs-stacking" class="md-nav__link">
    <span class="md-ellipsis">
      
        vs. Stacking
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vs-boosting" class="md-nav__link">
    <span class="md-ellipsis">
      
        vs. Boosting
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#13-theoretical-intuition-why-low-rank-helps" class="md-nav__link">
    <span class="md-ellipsis">
      
        13. Theoretical Intuition: Why Low-Rank Helps
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="13. Theoretical Intuition: Why Low-Rank Helps">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-low-rank-prior" class="md-nav__link">
    <span class="md-ellipsis">
      
        The Low-Rank Prior
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#what-the-latent-factors-capture" class="md-nav__link">
    <span class="md-ellipsis">
      
        What the Latent Factors Capture
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#14-advanced-variants-and-extensions" class="md-nav__link">
    <span class="md-ellipsis">
      
        14. Advanced Variants and Extensions
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="14. Advanced Variants and Extensions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#alternative-reconstruction-losses" class="md-nav__link">
    <span class="md-ellipsis">
      
        Alternative Reconstruction Losses
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#incorporating-additional-features" class="md-nav__link">
    <span class="md-ellipsis">
      
        Incorporating Additional Features
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hierarchical-structures" class="md-nav__link">
    <span class="md-ellipsis">
      
        Hierarchical Structures
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#attention-mechanisms" class="md-nav__link">
    <span class="md-ellipsis">
      
        Attention Mechanisms
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#15-practical-implementation-guide" class="md-nav__link">
    <span class="md-ellipsis">
      
        15. Practical Implementation Guide
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="15. Practical Implementation Guide">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#hyperparameters" class="md-nav__link">
    <span class="md-ellipsis">
      
        Hyperparameters
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#validation-strategy" class="md-nav__link">
    <span class="md-ellipsis">
      
        Validation Strategy
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#computational-considerations" class="md-nav__link">
    <span class="md-ellipsis">
      
        Computational Considerations
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#16-diagnostic-tools-and-debugging" class="md-nav__link">
    <span class="md-ellipsis">
      
        16. Diagnostic Tools and Debugging
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="16. Diagnostic Tools and Debugging">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#check-reconstruction-quality" class="md-nav__link">
    <span class="md-ellipsis">
      
        Check Reconstruction Quality
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#visualize-latent-spaces" class="md-nav__link">
    <span class="md-ellipsis">
      
        Visualize Latent Spaces
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#analyze-learned-weights" class="md-nav__link">
    <span class="md-ellipsis">
      
        Analyze Learned Weights
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#17-when-will-this-work-vs-stacking" class="md-nav__link">
    <span class="md-ellipsis">
      
        17. When Will This Work vs. Stacking?
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="17. When Will This Work vs. Stacking?">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#cf-ensemble-advantages" class="md-nav__link">
    <span class="md-ellipsis">
      
        CF-Ensemble Advantages
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#stacking-advantages" class="md-nav__link">
    <span class="md-ellipsis">
      
        Stacking Advantages
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#best-of-both-worlds" class="md-nav__link">
    <span class="md-ellipsis">
      
        Best of Both Worlds
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#18-mathematical-summary" class="md-nav__link">
    <span class="md-ellipsis">
      
        18. Mathematical Summary
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="18. Mathematical Summary">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#complete-formulation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Complete Formulation
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#19-philosophical-perspective" class="md-nav__link">
    <span class="md-ellipsis">
      
        19. Philosophical Perspective
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="19. Philosophical Perspective">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#learning-from-behavior-not-just-labels" class="md-nav__link">
    <span class="md-ellipsis">
      
        Learning from Behavior, Not Just Labels
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#from-compression-to-composition" class="md-nav__link">
    <span class="md-ellipsis">
      
        From Compression to Composition
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#20-research-directions-and-open-questions" class="md-nav__link">
    <span class="md-ellipsis">
      
        20. Research Directions and Open Questions
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="20. Research Directions and Open Questions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#theoretical-questions" class="md-nav__link">
    <span class="md-ellipsis">
      
        Theoretical Questions
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#algorithmic-improvements" class="md-nav__link">
    <span class="md-ellipsis">
      
        Algorithmic Improvements
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#applications" class="md-nav__link">
    <span class="md-ellipsis">
      
        Applications
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#21-conclusion" class="md-nav__link">
    <span class="md-ellipsis">
      
        21. Conclusion
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#references" class="md-nav__link">
    <span class="md-ellipsis">
      
        References
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../als_mathematical_derivation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    ALS Derivation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../als_vs_pytorch/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    ALS vs PyTorch
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../optimization/TECHNIQUES_SUMMARY/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Techniques Summary
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../optimization/class_weighted_gradients/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Class-Weighted Gradients
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../optimization/focal_loss/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Focal Loss
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../hyperparameter_tuning/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Hyperparameter Tuning
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../knowledge_distillation_tutorial/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Knowledge Distillation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_6" >
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Failure Modes
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            
  
    Failure Modes
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../failure_modes/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../failure_modes/aggregator_weight_collapse/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Aggregator Weight Collapse
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../failure_modes/transductive_vs_inductive/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Transductive vs Inductive
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../failure_modes/als_approximation_vs_exact_optimization/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    ALS Approximation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../failure_modes/optimization_instability/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Optimization Instability
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_7" >
        
          
          <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Notebooks
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7">
            <span class="md-nav__icon md-icon"></span>
            
  
    Notebooks
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../notebooks/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../notebooks/01_collaborative_filtering/Demo-Part1-CF_with_ALS/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Collaborative Filtering
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../notebooks/02_loss_functions/Demo-Part2-The_Role_of_Loss_Function_in_CF_Ensemble/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Loss Functions
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../notebooks/03_knn_ensemble/Demo-Part3-CF_Ensemble_with_kNNs/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    kNN Ensemble
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_7_5" >
        
          
          <label class="md-nav__link" for="__nav_7_5" id="__nav_7_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Stacking
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_7_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_5">
            <span class="md-nav__icon md-icon"></span>
            
  
    Stacking
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../notebooks/04_stacking/Demo-Part4-CF_Stacker/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    CF Stacker
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../notebooks/04_stacking/demo-stacking/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Stacking Demo
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_7_6" >
        
          
          <label class="md-nav__link" for="__nav_7_6" id="__nav_7_6_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Probability Filtering
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_7_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_6">
            <span class="md-nav__icon md-icon"></span>
            
  
    Probability Filtering
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../notebooks/05_probability_filtering/Demo-Part5-CF_Ensemble_via_Probability_Filtering/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Main Demo
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../notebooks/05_probability_filtering/Demo-Part5a-Alternative_Data_Representations_for_Probability_Filtering/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Alternative Representations
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../notebooks/05_probability_filtering/Demo-Part5b-Probability_Filtering_via_Custom_Loss/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Custom Loss
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_8" >
        
          
          <label class="md-nav__link" for="__nav_8" id="__nav_8_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Examples
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_8">
            <span class="md-nav__icon md-icon"></span>
            
  
    Examples
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../examples_README.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../examples_confidence_weighting_README.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Confidence Weighting
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_9" >
        
          
          <label class="md-nav__link" for="__nav_9" id="__nav_9_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Setup Guides
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_9_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_9">
            <span class="md-nav__icon md-icon"></span>
            
  
    Setup Guides
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../guides/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../guides/mkdocs_mathjax_setup_guide/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    MkDocs + MathJax Setup
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../guides/mkdocs_quick_reference/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Quick Reference
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#introduction" class="md-nav__link">
    <span class="md-ellipsis">
      
        Introduction
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#1-from-neural-networks-to-ensembles-the-structural-analogy" class="md-nav__link">
    <span class="md-ellipsis">
      
        1. From Neural Networks to Ensembles: The Structural Analogy
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="1. From Neural Networks to Ensembles: The Structural Analogy">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#knowledge-distillation-recap" class="md-nav__link">
    <span class="md-ellipsis">
      
        Knowledge Distillation Recap
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cf-ensemble-parallel" class="md-nav__link">
    <span class="md-ellipsis">
      
        CF-Ensemble Parallel
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-the-collaborative-filtering-view-of-ensemble-learning" class="md-nav__link">
    <span class="md-ellipsis">
      
        2. The Collaborative Filtering View of Ensemble Learning
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2. The Collaborative Filtering View of Ensemble Learning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#borrowing-from-recommender-systems" class="md-nav__link">
    <span class="md-ellipsis">
      
        Borrowing from Recommender Systems
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-probability-matrix" class="md-nav__link">
    <span class="md-ellipsis">
      
        The Probability Matrix
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3-matrix-factorization-finding-latent-structure" class="md-nav__link">
    <span class="md-ellipsis">
      
        3. Matrix Factorization: Finding Latent Structure
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3. Matrix Factorization: Finding Latent Structure">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#why-factorize" class="md-nav__link">
    <span class="md-ellipsis">
      
        Why Factorize?
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-factorization-model" class="md-nav__link">
    <span class="md-ellipsis">
      
        The Factorization Model
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reconstruction-via-inner-product" class="md-nav__link">
    <span class="md-ellipsis">
      
        Reconstruction via Inner Product
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4-the-reconstruction-loss-matching-the-ensemble" class="md-nav__link">
    <span class="md-ellipsis">
      
        4. The Reconstruction Loss: Matching the Ensemble
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4. The Reconstruction Loss: Matching the Ensemble">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#basic-squared-error" class="md-nav__link">
    <span class="md-ellipsis">
      
        Basic Squared Error
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#regularization" class="md-nav__link">
    <span class="md-ellipsis">
      
        Regularization
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5-confidence-weights-not-all-predictions-are-equal" class="md-nav__link">
    <span class="md-ellipsis">
      
        5. Confidence Weights: Not All Predictions Are Equal
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="5. Confidence Weights: Not All Predictions Are Equal">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-role-of-c" class="md-nav__link">
    <span class="md-ellipsis">
      
        The Role of \(C\)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#how-to-define-confidence" class="md-nav__link">
    <span class="md-ellipsis">
      
        How to Define Confidence
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#critical-insight" class="md-nav__link">
    <span class="md-ellipsis">
      
        Critical Insight
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#6-train-test-split-and-transductive-learning" class="md-nav__link">
    <span class="md-ellipsis">
      
        6. Train-Test Split and Transductive Learning
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="6. Train-Test Split and Transductive Learning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#data-partitioning" class="md-nav__link">
    <span class="md-ellipsis">
      
        Data Partitioning
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#why-this-makes-sense-for-ensemble-learning" class="md-nav__link">
    <span class="md-ellipsis">
      
        Why This Makes Sense for Ensemble Learning
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#constraints" class="md-nav__link">
    <span class="md-ellipsis">
      
        Constraints
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#7-the-supervised-loss-learning-what-signal-means" class="md-nav__link">
    <span class="md-ellipsis">
      
        7. The Supervised Loss: Learning What "Signal" Means
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="7. The Supervised Loss: Learning What &#34;Signal&#34; Means">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-aggregation-function" class="md-nav__link">
    <span class="md-ellipsis">
      
        The Aggregation Function
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#aggregation-choices" class="md-nav__link">
    <span class="md-ellipsis">
      
        Aggregation Choices
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-supervised-loss" class="md-nav__link">
    <span class="md-ellipsis">
      
        The Supervised Loss
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#8-the-complete-objective-putting-it-all-together" class="md-nav__link">
    <span class="md-ellipsis">
      
        8. The Complete Objective: Putting It All Together
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="8. The Complete Objective: Putting It All Together">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-kd-style-combined-loss" class="md-nav__link">
    <span class="md-ellipsis">
      
        The KD-Style Combined Loss
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#interpretation-of-rho" class="md-nav__link">
    <span class="md-ellipsis">
      
        Interpretation of \(\rho\)
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#9-why-this-formulation-addresses-previous-failures" class="md-nav__link">
    <span class="md-ellipsis">
      
        9. Why This Formulation Addresses Previous Failures
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="9. Why This Formulation Addresses Previous Failures">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-problem-with-pure-reconstruction" class="md-nav__link">
    <span class="md-ellipsis">
      
        The Problem with Pure Reconstruction
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#how-supervision-fixes-this" class="md-nav__link">
    <span class="md-ellipsis">
      
        How Supervision Fixes This
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-role-of-confidence-weights" class="md-nav__link">
    <span class="md-ellipsis">
      
        The Role of Confidence Weights
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#10-optimization-two-approaches" class="md-nav__link">
    <span class="md-ellipsis">
      
        10. Optimization: Two Approaches
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="10. Optimization: Two Approaches">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-challenge-non-quadratic-combined-loss" class="md-nav__link">
    <span class="md-ellipsis">
      
        The Challenge: Non-Quadratic Combined Loss
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#approach-1-als-with-label-aware-confidence-fast-approximation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Approach 1: ALS with Label-Aware Confidence (Fast Approximation)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#approach-2-joint-gradient-descent-via-pytorch-exact" class="md-nav__link">
    <span class="md-ellipsis">
      
        Approach 2: Joint Gradient Descent via PyTorch (Exact)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#which-approach-to-use" class="md-nav__link">
    <span class="md-ellipsis">
      
        Which Approach to Use?
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#11-test-time-inference" class="md-nav__link">
    <span class="md-ellipsis">
      
        11. Test-Time Inference
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="11. Test-Time Inference">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#reusing-classifier-factors" class="md-nav__link">
    <span class="md-ellipsis">
      
        Reusing Classifier Factors
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#truly-new-points-inductive-setting" class="md-nav__link">
    <span class="md-ellipsis">
      
        Truly New Points (Inductive Setting)
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#12-connection-to-other-ensemble-methods" class="md-nav__link">
    <span class="md-ellipsis">
      
        12. Connection to Other Ensemble Methods
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="12. Connection to Other Ensemble Methods">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#vs-simple-averaging" class="md-nav__link">
    <span class="md-ellipsis">
      
        vs. Simple Averaging
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vs-weighted-averaging" class="md-nav__link">
    <span class="md-ellipsis">
      
        vs. Weighted Averaging
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vs-stacking" class="md-nav__link">
    <span class="md-ellipsis">
      
        vs. Stacking
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vs-boosting" class="md-nav__link">
    <span class="md-ellipsis">
      
        vs. Boosting
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#13-theoretical-intuition-why-low-rank-helps" class="md-nav__link">
    <span class="md-ellipsis">
      
        13. Theoretical Intuition: Why Low-Rank Helps
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="13. Theoretical Intuition: Why Low-Rank Helps">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-low-rank-prior" class="md-nav__link">
    <span class="md-ellipsis">
      
        The Low-Rank Prior
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#what-the-latent-factors-capture" class="md-nav__link">
    <span class="md-ellipsis">
      
        What the Latent Factors Capture
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#14-advanced-variants-and-extensions" class="md-nav__link">
    <span class="md-ellipsis">
      
        14. Advanced Variants and Extensions
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="14. Advanced Variants and Extensions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#alternative-reconstruction-losses" class="md-nav__link">
    <span class="md-ellipsis">
      
        Alternative Reconstruction Losses
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#incorporating-additional-features" class="md-nav__link">
    <span class="md-ellipsis">
      
        Incorporating Additional Features
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hierarchical-structures" class="md-nav__link">
    <span class="md-ellipsis">
      
        Hierarchical Structures
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#attention-mechanisms" class="md-nav__link">
    <span class="md-ellipsis">
      
        Attention Mechanisms
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#15-practical-implementation-guide" class="md-nav__link">
    <span class="md-ellipsis">
      
        15. Practical Implementation Guide
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="15. Practical Implementation Guide">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#hyperparameters" class="md-nav__link">
    <span class="md-ellipsis">
      
        Hyperparameters
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#validation-strategy" class="md-nav__link">
    <span class="md-ellipsis">
      
        Validation Strategy
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#computational-considerations" class="md-nav__link">
    <span class="md-ellipsis">
      
        Computational Considerations
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#16-diagnostic-tools-and-debugging" class="md-nav__link">
    <span class="md-ellipsis">
      
        16. Diagnostic Tools and Debugging
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="16. Diagnostic Tools and Debugging">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#check-reconstruction-quality" class="md-nav__link">
    <span class="md-ellipsis">
      
        Check Reconstruction Quality
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#visualize-latent-spaces" class="md-nav__link">
    <span class="md-ellipsis">
      
        Visualize Latent Spaces
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#analyze-learned-weights" class="md-nav__link">
    <span class="md-ellipsis">
      
        Analyze Learned Weights
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#17-when-will-this-work-vs-stacking" class="md-nav__link">
    <span class="md-ellipsis">
      
        17. When Will This Work vs. Stacking?
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="17. When Will This Work vs. Stacking?">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#cf-ensemble-advantages" class="md-nav__link">
    <span class="md-ellipsis">
      
        CF-Ensemble Advantages
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#stacking-advantages" class="md-nav__link">
    <span class="md-ellipsis">
      
        Stacking Advantages
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#best-of-both-worlds" class="md-nav__link">
    <span class="md-ellipsis">
      
        Best of Both Worlds
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#18-mathematical-summary" class="md-nav__link">
    <span class="md-ellipsis">
      
        18. Mathematical Summary
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="18. Mathematical Summary">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#complete-formulation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Complete Formulation
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#19-philosophical-perspective" class="md-nav__link">
    <span class="md-ellipsis">
      
        19. Philosophical Perspective
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="19. Philosophical Perspective">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#learning-from-behavior-not-just-labels" class="md-nav__link">
    <span class="md-ellipsis">
      
        Learning from Behavior, Not Just Labels
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#from-compression-to-composition" class="md-nav__link">
    <span class="md-ellipsis">
      
        From Compression to Composition
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#20-research-directions-and-open-questions" class="md-nav__link">
    <span class="md-ellipsis">
      
        20. Research Directions and Open Questions
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="20. Research Directions and Open Questions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#theoretical-questions" class="md-nav__link">
    <span class="md-ellipsis">
      
        Theoretical Questions
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#algorithmic-improvements" class="md-nav__link">
    <span class="md-ellipsis">
      
        Algorithmic Improvements
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#applications" class="md-nav__link">
    <span class="md-ellipsis">
      
        Applications
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#21-conclusion" class="md-nav__link">
    <span class="md-ellipsis">
      
        21. Conclusion
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#references" class="md-nav__link">
    <span class="md-ellipsis">
      
        References
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              
              <article class="md-content__inner md-typeset">
                
                  


  
    <a href="https://github.com/pleiadian53/cf-ensemble/edit/main/docs/methods/cf_ensemble_optimization_objective_tutorial.md" title="Edit this page" class="md-content__button md-icon" rel="edit">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75z"/></svg>
    </a>
  
  


<h1 id="cf-ensemble-optimization-knowledge-distillation-meets-collaborative-filtering">CF-Ensemble Optimization: Knowledge Distillation Meets Collaborative Filtering<a class="headerlink" href="#cf-ensemble-optimization-knowledge-distillation-meets-collaborative-filtering" title="Permanent link">&para;</a></h1>
<p><strong>From soft targets to matrix factorization: A unified framework for ensemble learning</strong></p>
<hr />
<h2 id="introduction">Introduction<a class="headerlink" href="#introduction" title="Permanent link">&para;</a></h2>
<p>In the <a href="../knowledge_distillation_tutorial/">knowledge distillation tutorial</a>, we learned that effective learning combines two objectives:
1. <strong>Imitation</strong>: Match soft targets from a teacher
2. <strong>Supervision</strong>: Match hard labels from ground truth</p>
<p>This tutorial reveals a surprising connection: <strong>ensemble learning through collaborative filtering follows the exact same principle</strong>. Instead of distilling a single teacher model, we distill knowledge from an <em>ensemble</em> of base models through matrix factorization.</p>
<p>The key insight is that the probability matrixwhere base classifiers act as "teachers" for different data pointscan be decomposed to reveal latent factors that capture both:
- <strong>Reconstruction fidelity</strong>: Faithful representation of ensemble predictions
- <strong>Predictive accuracy</strong>: Alignment with true labels</p>
<p>This document develops the mathematical framework for CF-based ensemble learning, showing how knowledge distillation principles generalize to heterogeneous ensembles.</p>
<hr />
<h2 id="1-from-neural-networks-to-ensembles-the-structural-analogy">1. From Neural Networks to Ensembles: The Structural Analogy<a class="headerlink" href="#1-from-neural-networks-to-ensembles-the-structural-analogy" title="Permanent link">&para;</a></h2>
<h3 id="knowledge-distillation-recap">Knowledge Distillation Recap<a class="headerlink" href="#knowledge-distillation-recap" title="Permanent link">&para;</a></h3>
<p>In KD, we have:
- <strong>Teacher</strong>: Large model with soft predictions <span class="arithmatex">\(q_t\)</span>
- <strong>Student</strong>: Small model learning from <span class="arithmatex">\(q_t\)</span> and hard labels <span class="arithmatex">\(y_g\)</span>
- <strong>Loss</strong>: <span class="arithmatex">\(\mathcal{L}_{\text{KD}} = \rho \cdot L(\text{soft}) + (1-\rho) \cdot L(\text{hard})\)</span></p>
<h3 id="cf-ensemble-parallel">CF-Ensemble Parallel<a class="headerlink" href="#cf-ensemble-parallel" title="Permanent link">&para;</a></h3>
<p>In CF-ensemble, we have:
- <strong>"Teachers"</strong>: Base classifier predictions forming probability matrix <span class="arithmatex">\(R\)</span>
- <strong>"Student"</strong>: Latent factor model reconstructing <span class="arithmatex">\(R\)</span> and predicting labels
- <strong>Loss</strong>: <span class="arithmatex">\(\mathcal{L}_{\text{CF}} = \rho \cdot L(\text{recon}) + (1-\rho) \cdot L(\text{supervised})\)</span></p>
<p><strong>The skeleton is identicalonly the organs differ.</strong></p>
<table>
<thead>
<tr>
<th>Concept</th>
<th>Knowledge Distillation</th>
<th>CF-Ensemble</th>
</tr>
</thead>
<tbody>
<tr>
<td>Teacher knowledge</td>
<td>Soft probability distribution</td>
<td>Probability matrix <span class="arithmatex">\(R\)</span></td>
</tr>
<tr>
<td>Student model</td>
<td>Small neural network</td>
<td>Latent factors <span class="arithmatex">\(X, Y\)</span></td>
</tr>
<tr>
<td>Soft matching</td>
<td>KL divergence</td>
<td>Reconstruction loss</td>
</tr>
<tr>
<td>Hard matching</td>
<td>Cross-entropy with labels</td>
<td>Supervised aggregation</td>
</tr>
<tr>
<td>Trade-off</td>
<td><span class="arithmatex">\(\rho\)</span></td>
<td><span class="arithmatex">\(\rho\)</span></td>
</tr>
</tbody>
</table>
<hr />
<h2 id="2-the-collaborative-filtering-view-of-ensemble-learning">2. The Collaborative Filtering View of Ensemble Learning<a class="headerlink" href="#2-the-collaborative-filtering-view-of-ensemble-learning" title="Permanent link">&para;</a></h2>
<h3 id="borrowing-from-recommender-systems">Borrowing from Recommender Systems<a class="headerlink" href="#borrowing-from-recommender-systems" title="Permanent link">&para;</a></h3>
<p>In collaborative filtering for recommender systems:
- <strong>Users</strong> rate <strong>items</strong>
- We factorize the rating matrix to find latent preferences
- Predictions are reconstructed via dot products of latent vectors</p>
<p>In our ensemble context:
- <strong>Base classifiers</strong> (users) "rate" <strong>data points</strong> (items)
- "Ratings" are predicted probabilities <span class="arithmatex">\(P(y=1 \mid x)\)</span>
- We factorize to find latent factors explaining predictions</p>
<p>This is more than analogyit's a direct mathematical mapping.</p>
<h3 id="the-probability-matrix">The Probability Matrix<a class="headerlink" href="#the-probability-matrix" title="Permanent link">&para;</a></h3>
<p>Define the <strong>probability (rating) matrix</strong>:
$<span class="arithmatex">\(R \in [0,1]^{m \times n}\)</span>$</p>
<p>where:
- <span class="arithmatex">\(m\)</span> = number of base classifiers
- <span class="arithmatex">\(n\)</span> = number of data points (train + test)
- <span class="arithmatex">\(r_{ui}\)</span> = classifier <span class="arithmatex">\(u\)</span>'s predicted probability for point <span class="arithmatex">\(i\)</span></p>
<div class="arithmatex">\[r_{ui} = P_u(y=1 \mid x_i)\]</div>
<p>This matrix encodes the entire ensemble's predictions across all data points.</p>
<hr />
<h2 id="3-matrix-factorization-finding-latent-structure">3. Matrix Factorization: Finding Latent Structure<a class="headerlink" href="#3-matrix-factorization-finding-latent-structure" title="Permanent link">&para;</a></h2>
<h3 id="why-factorize">Why Factorize?<a class="headerlink" href="#why-factorize" title="Permanent link">&para;</a></h3>
<p>The probability matrix <span class="arithmatex">\(R\)</span> is noisy and redundant:
- Different classifiers make correlated errors
- Some patterns are genuine signal (related to true labels)
- Other patterns are noise (systematic biases, overfitting)</p>
<p>Matrix factorization <strong>separates signal from noise</strong> by finding low-dimensional latent representations.</p>
<h3 id="the-factorization-model">The Factorization Model<a class="headerlink" href="#the-factorization-model" title="Permanent link">&para;</a></h3>
<p>We approximate <span class="arithmatex">\(R\)</span> using latent vectors:</p>
<p><strong>Classifier latent factors</strong>:
$<span class="arithmatex">\(X = [x_1, x_2, \ldots, x_m] \in \mathbb{R}^{d \times m}\)</span>$</p>
<p>where <span class="arithmatex">\(x_u \in \mathbb{R}^d\)</span> is the <span class="arithmatex">\(d\)</span>-dimensional latent vector for classifier <span class="arithmatex">\(u\)</span>.</p>
<p><strong>Instance latent factors</strong>:
$<span class="arithmatex">\(Y = [y_1, y_2, \ldots, y_n] \in \mathbb{R}^{d \times n}\)</span>$</p>
<p>where <span class="arithmatex">\(y_i \in \mathbb{R}^d\)</span> is the <span class="arithmatex">\(d\)</span>-dimensional latent vector for data point <span class="arithmatex">\(i\)</span>.</p>
<h3 id="reconstruction-via-inner-product">Reconstruction via Inner Product<a class="headerlink" href="#reconstruction-via-inner-product" title="Permanent link">&para;</a></h3>
<p>The predicted probability is:
$<span class="arithmatex">\(\hat{r}_{ui} = x_u^\top y_i = \sum_{k=1}^d x_{uk} \cdot y_{ik}\)</span>$</p>
<p>This dot product measures <strong>alignment in latent space</strong>: classifiers and data points with similar latent factors produce similar probabilities.</p>
<hr />
<h2 id="4-the-reconstruction-loss-matching-the-ensemble">4. The Reconstruction Loss: Matching the Ensemble<a class="headerlink" href="#4-the-reconstruction-loss-matching-the-ensemble" title="Permanent link">&para;</a></h2>
<h3 id="basic-squared-error">Basic Squared Error<a class="headerlink" href="#basic-squared-error" title="Permanent link">&para;</a></h3>
<p>The simplest reconstruction objective is weighted squared error:</p>
<div class="arithmatex">\[L_{\text{recon}}(X, Y) = \sum_{u=1}^m \sum_{i=1}^n c_{ui} \left( r_{ui} - x_u^\top y_i \right)^2\]</div>
<p>where <span class="arithmatex">\(c_{ui} &gt; 0\)</span> are <strong>confidence weights</strong> (discussed below).</p>
<p><strong>Interpretation</strong>: Find latent factors that faithfully reproduce the observed probabilities.</p>
<h3 id="regularization">Regularization<a class="headerlink" href="#regularization" title="Permanent link">&para;</a></h3>
<p>To prevent overfitting, we add <span class="arithmatex">\(\ell_2\)</span> regularization:</p>
<div class="arithmatex">\[L_{\text{recon}}(X, Y) = \sum_{u=1}^m \sum_{i=1}^n c_{ui} \left( r_{ui} - x_u^\top y_i \right)^2 + \lambda \left( \sum_{u=1}^m \|x_u\|^2 + \sum_{i=1}^n \|y_i\|^2 \right)\]</div>
<p>where <span class="arithmatex">\(\lambda &gt; 0\)</span> controls regularization strength.</p>
<p><strong>This is analogous to the teacher-matching term in KD</strong>: we're learning to imitate the ensemble's predictions.</p>
<hr />
<h2 id="5-confidence-weights-not-all-predictions-are-equal">5. Confidence Weights: Not All Predictions Are Equal<a class="headerlink" href="#5-confidence-weights-not-all-predictions-are-equal" title="Permanent link">&para;</a></h2>
<h3 id="the-role-of-c">The Role of <span class="arithmatex">\(C\)</span><a class="headerlink" href="#the-role-of-c" title="Permanent link">&para;</a></h3>
<p>The confidence matrix <span class="arithmatex">\(C \in \mathbb{R}_+^{m \times n}\)</span> encodes our trust in each probability:</p>
<div class="arithmatex">\[c_{ui} = \text{confidence}(r_{ui})\]</div>
<p>Higher <span class="arithmatex">\(c_{ui}\)</span> means:
- We trust classifier <span class="arithmatex">\(u\)</span>'s prediction for point <span class="arithmatex">\(i\)</span> more
- Reconstruction error on this entry is weighted more heavily
- Latent factors are pulled to match this prediction more strongly</p>
<h3 id="how-to-define-confidence">How to Define Confidence<a class="headerlink" href="#how-to-define-confidence" title="Permanent link">&para;</a></h3>
<p>Several approaches work:</p>
<h4 id="1-calibration-based-confidence">1. Calibration-Based Confidence<a class="headerlink" href="#1-calibration-based-confidence" title="Permanent link">&para;</a></h4>
<p>Use calibration metrics like <strong>Brier score</strong>:
$<span class="arithmatex">\(c_{ui} = 1 - \text{Brier}_u = 1 - \frac{1}{N}\sum_{j} (r_{uj} - y_j)^2\)</span>$</p>
<p>Better-calibrated classifiers get higher weight.</p>
<h4 id="2-prediction-certainty">2. Prediction Certainty<a class="headerlink" href="#2-prediction-certainty" title="Permanent link">&para;</a></h4>
<p>Use distance from 0.5 (uncertainty):
$<span class="arithmatex">\(c_{ui} = |r_{ui} - 0.5|\)</span>$</p>
<p>Confident predictions (close to 0 or 1) get higher weight.</p>
<h4 id="3-ensemble-agreement">3. Ensemble Agreement<a class="headerlink" href="#3-ensemble-agreement" title="Permanent link">&para;</a></h4>
<p>Use variance across classifiers:
$<span class="arithmatex">\(c_{ui} = 1 - \text{Var}_u(r_{\cdot i})\)</span>$</p>
<p>Points with high ensemble agreement get higher weight.</p>
<h4 id="4-label-aware-confidence-for-labeled-data">4. Label-Aware Confidence (for labeled data)<a class="headerlink" href="#4-label-aware-confidence-for-labeled-data" title="Permanent link">&para;</a></h4>
<p>For <span class="arithmatex">\(i \in \mathcal{L}\)</span> (labeled points):
$<span class="arithmatex">\(c_{ui} = \begin{cases}
r_{ui} &amp; \text{if } y_i = 1 \text{ (reward correct high predictions)} \\
1 - r_{ui} &amp; \text{if } y_i = 0 \text{ (reward correct low predictions)}
\end{cases}\)</span>$</p>
<p>This explicitly upweights predictions consistent with labels.</p>
<h3 id="critical-insight">Critical Insight<a class="headerlink" href="#critical-insight" title="Permanent link">&para;</a></h3>
<p><strong>The confidence matrix is how we encode which predictions are "signal" vs "noise"</strong>. Without it, reconstruction treats all probabilities equally, including systematic errors we want to suppress.</p>
<hr />
<h2 id="6-train-test-split-and-transductive-learning">6. Train-Test Split and Transductive Learning<a class="headerlink" href="#6-train-test-split-and-transductive-learning" title="Permanent link">&para;</a></h2>
<h3 id="data-partitioning">Data Partitioning<a class="headerlink" href="#data-partitioning" title="Permanent link">&para;</a></h3>
<p>We split data points into:
- <strong>Labeled set</strong> <span class="arithmatex">\(\mathcal{L}\)</span>: Training data with known labels <span class="arithmatex">\(y_i\)</span>
- <strong>Unlabeled set</strong> <span class="arithmatex">\(\mathcal{U}\)</span>: Test data with masked labels</p>
<p>Crucially, <strong>both sets are used during training</strong>, but labels are only available for <span class="arithmatex">\(\mathcal{L}\)</span>.</p>
<p>This is <strong>transductive</strong> or <strong>semi-supervised</strong> learning: we observe test inputs (and their base model predictions) at training time, but not their labels.</p>
<h3 id="why-this-makes-sense-for-ensemble-learning">Why This Makes Sense for Ensemble Learning<a class="headerlink" href="#why-this-makes-sense-for-ensemble-learning" title="Permanent link">&para;</a></h3>
<p>Unlike typical ML, in ensemble contexts:
- Base models have <em>already</em> made predictions on test data
- We have access to the probability matrix <span class="arithmatex">\(R\)</span> for all points
- We want to learn how to aggregate these existing predictions</p>
<p>The transductive setting is <strong>natural for this problem</strong>: we're not training base models, we're learning to combine their outputs.</p>
<h3 id="constraints">Constraints<a class="headerlink" href="#constraints" title="Permanent link">&para;</a></h3>
<p>During training:
- <strong>Classifier factors <span class="arithmatex">\(X\)</span></strong>: Learned from all data (train + test)
- <strong>Train instance factors <span class="arithmatex">\(Y_{\mathcal{L}}\)</span></strong>: Learned using reconstruction + supervision
- <strong>Test instance factors <span class="arithmatex">\(Y_{\mathcal{U}}\)</span></strong>: Learned using reconstruction only (no labels)</p>
<hr />
<h2 id="7-the-supervised-loss-learning-what-signal-means">7. The Supervised Loss: Learning What "Signal" Means<a class="headerlink" href="#7-the-supervised-loss-learning-what-signal-means" title="Permanent link">&para;</a></h2>
<h3 id="the-aggregation-function">The Aggregation Function<a class="headerlink" href="#the-aggregation-function" title="Permanent link">&para;</a></h3>
<p>For each data point <span class="arithmatex">\(i\)</span>, we aggregate reconstructed probabilities into a final prediction.</p>
<p>Collect the reconstructed probabilities across all classifiers:
$<span class="arithmatex">\(\hat{r}_{\cdot i} = [\hat{r}_{1i}, \hat{r}_{2i}, \ldots, \hat{r}_{mi}] \in \mathbb{R}^m\)</span>$</p>
<p>Define an <strong>aggregation function</strong> <span class="arithmatex">\(g: \mathbb{R}^m \to [0,1]\)</span>:
$<span class="arithmatex">\(\hat{p}_i = g(\hat{r}_{\cdot i})\)</span>$</p>
<p>This is our final predicted probability for point <span class="arithmatex">\(i\)</span>.</p>
<h3 id="aggregation-choices">Aggregation Choices<a class="headerlink" href="#aggregation-choices" title="Permanent link">&para;</a></h3>
<p><strong>Simple mean</strong>:
$<span class="arithmatex">\(g(\hat{r}_{\cdot i}) = \frac{1}{m} \sum_{u=1}^m \hat{r}_{ui}\)</span>$</p>
<p><strong>Weighted mean</strong> (learnable weights <span class="arithmatex">\(w\)</span>):
$<span class="arithmatex">\(g(\hat{r}_{\cdot i}) = \sigma\left( w^\top \hat{r}_{\cdot i} + b \right)\)</span>$
where <span class="arithmatex">\(\sigma\)</span> is sigmoid.</p>
<p><strong>Stacker model</strong> (meta-learner):
$<span class="arithmatex">\(g(\hat{r}_{\cdot i}) = \text{MLP}(\hat{r}_{\cdot i})\)</span>$</p>
<p><strong>Note</strong>: Simpler is often better to avoid overfitting. Start with mean or weighted mean.</p>
<h3 id="the-supervised-loss">The Supervised Loss<a class="headerlink" href="#the-supervised-loss" title="Permanent link">&para;</a></h3>
<p>For labeled points, we use binary cross-entropy:</p>
<div class="arithmatex">\[L_{\text{sup}}(X, Y, \theta) = \sum_{i \in \mathcal{L}} \text{CE}(y_i, g_\theta(\hat{r}_{\cdot i}))\]</div>
<p>where:
$<span class="arithmatex">\(\text{CE}(y_i, \hat{p}_i) = -y_i \log \hat{p}_i - (1-y_i) \log(1-\hat{p}_i)\)</span>$</p>
<p>and <span class="arithmatex">\(\theta\)</span> represents parameters of the aggregator <span class="arithmatex">\(g_\theta\)</span>.</p>
<p><strong>This is analogous to the hard label term in KD</strong>: we're ensuring the model predicts the correct labels, not just reconstructs probabilities.</p>
<hr />
<h2 id="8-the-complete-objective-putting-it-all-together">8. The Complete Objective: Putting It All Together<a class="headerlink" href="#8-the-complete-objective-putting-it-all-together" title="Permanent link">&para;</a></h2>
<h3 id="the-kd-style-combined-loss">The KD-Style Combined Loss<a class="headerlink" href="#the-kd-style-combined-loss" title="Permanent link">&para;</a></h3>
<div class="arithmatex">\[\boxed{
\mathcal{L}_{\text{CF-Ensemble}}(X, Y, \theta) = \rho \cdot L_{\text{recon}}(X, Y) + (1-\rho) \cdot L_{\text{sup}}(X, Y, \theta)
}\]</div>
<p>Expanding the components:</p>
<div class="arithmatex">\[\begin{align}
\mathcal{L}_{\text{CF-Ensemble}} &amp;= \rho \left[ \sum_{u,i} c_{ui}(r_{ui} - x_u^\top y_i)^2 + \lambda(\|X\|_F^2 + \|Y\|_F^2) \right] \\
&amp;\quad + (1-\rho) \sum_{i \in \mathcal{L}} \text{CE}(y_i, g_\theta(\hat{r}_{\cdot i}))
\end{align}\]</div>
<p>where:
- <strong>First term</strong>: Matrix reconstruction (all points, weighted by confidence)
- <strong>Second term</strong>: Supervised prediction (labeled points only)
- <strong><span class="arithmatex">\(\rho \in [0,1]\)</span></strong>: Trade-off between reconstruction fidelity and predictive accuracy</p>
<h3 id="interpretation-of-rho">Interpretation of <span class="arithmatex">\(\rho\)</span><a class="headerlink" href="#interpretation-of-rho" title="Permanent link">&para;</a></h3>
<ul>
<li><strong><span class="arithmatex">\(\rho = 1\)</span></strong>: Pure matrix factorization (no supervision)</li>
<li>Faithfully reconstructs probabilities</li>
<li>No guarantee of good predictions</li>
<li>
<p>Reproduces base model mistakes</p>
</li>
<li>
<p><strong><span class="arithmatex">\(\rho = 0\)</span></strong>: Pure supervised stacking (no CF)</p>
</li>
<li>Learns aggregation from labels only</li>
<li>Ignores probability structure</li>
<li>
<p>Reduces to standard stacking</p>
</li>
<li>
<p><strong><span class="arithmatex">\(\rho \in (0.3, 0.7)\)</span></strong>: Balanced approach</p>
</li>
<li>Leverages both probability structure and labels</li>
<li>Learns which patterns are signal vs noise</li>
<li><strong>Recommended starting range</strong></li>
</ul>
<hr />
<h2 id="9-why-this-formulation-addresses-previous-failures">9. Why This Formulation Addresses Previous Failures<a class="headerlink" href="#9-why-this-formulation-addresses-previous-failures" title="Permanent link">&para;</a></h2>
<h3 id="the-problem-with-pure-reconstruction">The Problem with Pure Reconstruction<a class="headerlink" href="#the-problem-with-pure-reconstruction" title="Permanent link">&para;</a></h3>
<p>Your earlier attempts used primarily <span class="arithmatex">\(L_{\text{recon}}\)</span>, which has a fundamental flaw:</p>
<blockquote>
<p><strong>Optimizing squared error on probabilities encourages reconstructing the ensemble <em>as is</em>, including systematic errors.</strong></p>
</blockquote>
<p>If multiple base models consistently misclassify certain regions:
- The reconstruction will faithfully reproduce these errors
- Low-rank factorization will <em>smooth</em> these errors across similar points
- The result: amplification of systematic biases</p>
<h3 id="how-supervision-fixes-this">How Supervision Fixes This<a class="headerlink" href="#how-supervision-fixes-this" title="Permanent link">&para;</a></h3>
<p>Adding <span class="arithmatex">\(L_{\text{sup}}\)</span> teaches the system <strong>what "signal" means</strong>:
- Reconstruction patterns consistent with labels  amplified
- Reconstruction patterns inconsistent with labels  suppressed
- The model learns to distinguish true predictive signal from noise</p>
<p>This is exactly why KD combines soft and hard targets!</p>
<h3 id="the-role-of-confidence-weights">The Role of Confidence Weights<a class="headerlink" href="#the-role-of-confidence-weights" title="Permanent link">&para;</a></h3>
<p>For labeled data (<span class="arithmatex">\(i \in \mathcal{L}\)</span>), using label-aware confidence:
$<span class="arithmatex">\(c_{ui} = \begin{cases}
r_{ui} &amp; \text{if } y_i = 1 \\
1 - r_{ui} &amp; \text{if } y_i = 0
\end{cases}\)</span>$</p>
<p>means reconstruction preferentially matches <strong>correct predictions</strong>:
- True Positives (high <span class="arithmatex">\(r_{ui}\)</span> for <span class="arithmatex">\(y_i=1\)</span>)  high weight
- True Negatives (low <span class="arithmatex">\(r_{ui}\)</span> for <span class="arithmatex">\(y_i=0\)</span>)  high weight
- False Positives (high <span class="arithmatex">\(r_{ui}\)</span> for <span class="arithmatex">\(y_i=0\)</span>)  low weight
- False Negatives (low <span class="arithmatex">\(r_{ui}\)</span> for <span class="arithmatex">\(y_i=1\)</span>)  low weight</p>
<p>This is your "TP/TN amplification, FP/FN suppression" idea, formalized.</p>
<hr />
<h2 id="10-optimization-two-approaches">10. Optimization: Two Approaches<a class="headerlink" href="#10-optimization-two-approaches" title="Permanent link">&para;</a></h2>
<h3 id="the-challenge-non-quadratic-combined-loss">The Challenge: Non-Quadratic Combined Loss<a class="headerlink" href="#the-challenge-non-quadratic-combined-loss" title="Permanent link">&para;</a></h3>
<p>Our combined objective is:
$<span class="arithmatex">\(\mathcal{L}_{\text{CF}} = \rho \cdot \underbrace{\sum c_{ui}(r_{ui} - x_u^\top y_i)^2}_{\text{quadratic}} + (1-\rho) \cdot \underbrace{\sum CE(y_i, g_\theta(X^\top y_i))}_{\text{NON-quadratic}}\)</span>$</p>
<p><strong>The problem:</strong>
- Reconstruction term is quadratic  Closed-form ALS possible
- Supervised term contains <span class="arithmatex">\(\sigma(\cdot)\)</span> and <span class="arithmatex">\(\log(\cdot)\)</span>  <strong>No closed-form solution</strong></p>
<p><strong>Conclusion:</strong> Cannot derive closed-form ALS for the full combined loss.</p>
<p><strong>Analogy:</strong> Like VAE or KD, modern combined objectives require gradient descent, not closed-form.</p>
<h3 id="approach-1-als-with-label-aware-confidence-fast-approximation">Approach 1: ALS with Label-Aware Confidence (Fast Approximation)<a class="headerlink" href="#approach-1-als-with-label-aware-confidence-fast-approximation" title="Permanent link">&para;</a></h3>
<p><strong>Strategy:</strong> Approximate the combined loss by encoding supervision via confidence weights.</p>
<p>Instead of optimizing <span class="arithmatex">\(\mathcal{L}_{\text{CF}}\)</span> directly, optimize:
$<span class="arithmatex">\(\mathcal{L}_{\text{approx}} = \sum_{u,i} \tilde{c}_{ui}(r_{ui} - x_u^\top y_i)^2 + \lambda(\|X\|_F^2 + \|Y\|_F^2)\)</span>$</p>
<p>where <span class="arithmatex">\(\tilde{c}_{ui}\)</span> is <strong>label-aware</strong>:
$<span class="arithmatex">\(\tilde{c}_{ui} = \begin{cases}
c_{ui}^{\text{base}} \cdot (1 + \alpha \cdot r_{ui}) &amp; \text{if } y_i = 1 \\
c_{ui}^{\text{base}} \cdot (1 + \alpha \cdot (1 - r_{ui})) &amp; \text{if } y_i = 0 \\
c_{ui}^{\text{base}} &amp; \text{if unlabeled}
\end{cases}\)</span>$</p>
<p><strong>How this incorporates supervision:</strong>
- Predictions matching labels get higher confidence  ALS preserves them
- Predictions contradicting labels get lower confidence  ALS discards them
- Unlabeled predictions use base confidence (e.g., certainty <span class="arithmatex">\(|r_{ui} - 0.5|\)</span>)</p>
<p><strong>ALS update equations (same form, but use <span class="arithmatex">\(\tilde{C}\)</span>):</strong></p>
<p><strong>Fix <span class="arithmatex">\(Y\)</span>, update <span class="arithmatex">\(X\)</span></strong>:
$<span class="arithmatex">\(x_u = \left( Y \tilde{C}_u Y^\top + \lambda I \right)^{-1} Y \tilde{C}_u r_u\)</span>$</p>
<p><strong>Fix <span class="arithmatex">\(X\)</span>, update <span class="arithmatex">\(Y\)</span></strong>:
$<span class="arithmatex">\(y_i = \left( X \tilde{C}_i X^\top + \lambda I \right)^{-1} X \tilde{C}_i r_i\)</span>$</p>
<p><strong>Aggregator update:</strong>
$<span class="arithmatex">\(\theta \leftarrow \theta - \eta \nabla_\theta L_{\text{sup}}(X, Y, \theta)\)</span>$</p>
<p><strong>Algorithm:</strong>
<div class="language-text highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a>1. Initialize X, Y randomly
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>2. Compute label-aware confidence C
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>3. For each iteration:
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>   a. Fix Y, update X via ALS using C
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>   b. Fix X, update Y via ALS using C
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>   c. Fix X, Y, update  via gradient descent
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>   d. Check convergence on L_CF (not L_approx)
</span><span id="__span-0-8"><a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>4. Return X, Y, 
</span></code></pre></div></p>
<p><strong>Computational complexity:</strong>
- Each ALS update: <span class="arithmatex">\(O(d^3 + d^2n)\)</span> or <span class="arithmatex">\(O(d^3 + d^2m)\)</span>
- Parallelizable across classifiers/instances
- Typically 50-200 iterations</p>
<p><strong>Advantages:</strong>
-  Fast per iteration (closed-form)
-  Works with NumPy only
-  Reasonable approximation (90-95% of exact)</p>
<p><strong>Disadvantages:</strong>
-  Approximate (not exact gradient)
-  Extra hyperparameter ()
-  May have convergence issues</p>
<h3 id="approach-2-joint-gradient-descent-via-pytorch-exact">Approach 2: Joint Gradient Descent via PyTorch (Exact)<a class="headerlink" href="#approach-2-joint-gradient-descent-via-pytorch-exact" title="Permanent link">&para;</a></h3>
<p><strong>Strategy:</strong> Directly optimize <span class="arithmatex">\(\mathcal{L}_{\text{CF}}\)</span> using automatic differentiation.</p>
<p><strong>Unified gradients:</strong>
$<span class="arithmatex">\(\begin{align}
\nabla_X \mathcal{L}_{\text{CF}} &amp;= \rho \cdot \nabla_X L_{\text{recon}} + (1-\rho) \cdot \nabla_X L_{\text{sup}} \\
\nabla_Y \mathcal{L}_{\text{CF}} &amp;= \rho \cdot \nabla_Y L_{\text{recon}} + (1-\rho) \cdot \nabla_Y L_{\text{sup}} \\
\nabla_\theta \mathcal{L}_{\text{CF}} &amp;= (1-\rho) \cdot \nabla_\theta L_{\text{sup}}
\end{align}\)</span>$</p>
<p><strong>Update equations:</strong>
$<span class="arithmatex">\(\begin{align}
X &amp;\leftarrow X - \eta_X \cdot \nabla_X \mathcal{L}_{\text{CF}} \\
Y &amp;\leftarrow Y - \eta_Y \cdot \nabla_Y \mathcal{L}_{\text{CF}} \\
\theta &amp;\leftarrow \theta - \eta_\theta \cdot \nabla_\theta \mathcal{L}_{\text{CF}}
\end{align}\)</span>$</p>
<p><strong>Algorithm:</strong>
<div class="language-text highlight"><pre><span></span><code><span id="__span-1-1"><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a>1. Initialize X, Y,  as PyTorch parameters
</span><span id="__span-1-2"><a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a>2. For each epoch:
</span><span id="__span-1-3"><a id="__codelineno-1-3" name="__codelineno-1-3" href="#__codelineno-1-3"></a>   a. Forward: Compute R = X^T Y,  = g_(R)
</span><span id="__span-1-4"><a id="__codelineno-1-4" name="__codelineno-1-4" href="#__codelineno-1-4"></a>   b. Loss: L_CF = L_recon + (1-)L_sup
</span><span id="__span-1-5"><a id="__codelineno-1-5" name="__codelineno-1-5" href="#__codelineno-1-5"></a>   c. Backward: loss.backward() (computes all gradients)
</span><span id="__span-1-6"><a id="__codelineno-1-6" name="__codelineno-1-6" href="#__codelineno-1-6"></a>   d. Update: optimizer.step() (updates X, Y,  together)
</span><span id="__span-1-7"><a id="__codelineno-1-7" name="__codelineno-1-7" href="#__codelineno-1-7"></a>3. Return X, Y, 
</span></code></pre></div></p>
<p><strong>Computational complexity:</strong>
- Forward pass: <span class="arithmatex">\(O(dmn)\)</span> for reconstruction + <span class="arithmatex">\(O(mn)\)</span> for aggregation
- Backward pass: Same as forward (autodiff)
- Typically 50-200 epochs
- GPU acceleration: 10-100x speedup</p>
<p><strong>Advantages:</strong>
-  Exact (true gradient of <span class="arithmatex">\(\mathcal{L}_{\text{CF}}\)</span>)
-  Unified (all parameters updated consistently)
-  Flexible (easy to extend)
-  GPU acceleration</p>
<p><strong>Disadvantages:</strong>
-  Requires PyTorch
-  Slower per iteration on CPU
-  More hyperparameters (learning rates, optimizer)</p>
<h3 id="which-approach-to-use">Which Approach to Use?<a class="headerlink" href="#which-approach-to-use" title="Permanent link">&para;</a></h3>
<p><strong>Use ALS when:</strong>
- CPU-only environment
- Speed is critical (real-time, frequent retraining)
- Simple is better (no ML framework)
- Approximation is acceptable</p>
<p><strong>Use PyTorch when:</strong>
- GPU available
- Accuracy is critical (research, production SLAs)
- Want advanced features (attention, deep aggregators)
- Already using PyTorch in pipeline</p>
<p><strong>Recommendation:</strong> Start with ALS for prototyping, switch to PyTorch for production optimization.</p>
<p><strong>See also:</strong>
- <code>docs/methods/als_mathematical_derivation.md</code> - Full ALS derivation
- <code>docs/methods/als_vs_pytorch.md</code> - Detailed comparison
- <code>docs/failure_modes/als_approximation_vs_exact_optimization.md</code> - Why approximation needed</p>
<hr />
<h2 id="11-test-time-inference">11. Test-Time Inference<a class="headerlink" href="#11-test-time-inference" title="Permanent link">&para;</a></h2>
<h3 id="reusing-classifier-factors">Reusing Classifier Factors<a class="headerlink" href="#reusing-classifier-factors" title="Permanent link">&para;</a></h3>
<p>At test time:
- <strong>Classifier factors <span class="arithmatex">\(X\)</span> are fixed</strong> (classifiers don't change)
- <strong>Test point factors <span class="arithmatex">\(Y_{\mathcal{U}}\)</span> are already learned</strong> (from transductive training)
- Simply aggregate: <span class="arithmatex">\(\hat{p}_i = g_\theta(\hat{r}_{\cdot i})\)</span> where <span class="arithmatex">\(\hat{r}_{ui} = x_u^\top y_i\)</span></p>
<h3 id="truly-new-points-inductive-setting">Truly New Points (Inductive Setting)<a class="headerlink" href="#truly-new-points-inductive-setting" title="Permanent link">&para;</a></h3>
<p>For a completely new point <span class="arithmatex">\(i_{\text{new}}\)</span> not seen during training:</p>
<ol>
<li>Obtain base model predictions: <span class="arithmatex">\(r_{1,i_{\text{new}}}, \ldots, r_{m,i_{\text{new}}}\)</span></li>
<li>Solve for its latent factor (fix <span class="arithmatex">\(X\)</span>):
   $<span class="arithmatex">\(y_{i_{\text{new}}} = (X C_{i_{\text{new}}} X^\top + \lambda I)^{-1} X C_{i_{\text{new}}} r_{i_{\text{new}}}\)</span>$</li>
<li>Reconstruct: <span class="arithmatex">\(\hat{r}_{u,i_{\text{new}}} = x_u^\top y_{i_{\text{new}}}\)</span></li>
<li>Aggregate: <span class="arithmatex">\(\hat{p}_{i_{\text{new}}} = g_\theta(\hat{r}_{\cdot, i_{\text{new}}})\)</span></li>
</ol>
<p>This is analogous to "cold-start" solutions in recommender systems.</p>
<hr />
<h2 id="12-connection-to-other-ensemble-methods">12. Connection to Other Ensemble Methods<a class="headerlink" href="#12-connection-to-other-ensemble-methods" title="Permanent link">&para;</a></h2>
<h3 id="vs-simple-averaging">vs. Simple Averaging<a class="headerlink" href="#vs-simple-averaging" title="Permanent link">&para;</a></h3>
<p><strong>Simple averaging</strong>: <span class="arithmatex">\(\hat{p}_i = \frac{1}{m}\sum_u r_{ui}\)</span>
- Treats all classifiers equally
- No adaptation to data regions
- Our method: learns <strong>context-dependent weights</strong> via latent factors</p>
<h3 id="vs-weighted-averaging">vs. Weighted Averaging<a class="headerlink" href="#vs-weighted-averaging" title="Permanent link">&para;</a></h3>
<p><strong>Weighted averaging</strong>: <span class="arithmatex">\(\hat{p}_i = \sum_u w_u r_{ui}\)</span>
- Global weights for each classifier
- No adaptation to specific points
- Our method: weights are <strong>instance-specific</strong> via <span class="arithmatex">\(x_u^\top y_i\)</span></p>
<h3 id="vs-stacking">vs. Stacking<a class="headerlink" href="#vs-stacking" title="Permanent link">&para;</a></h3>
<p><strong>Stacking</strong>: Train meta-learner <span class="arithmatex">\(g(r_{1i}, \ldots, r_{mi}) \to y_i\)</span>
- Can overfit if not careful
- Doesn't leverage unlabeled data structure
- Our method: <strong>regularizes via reconstruction</strong> and uses transductive information</p>
<h3 id="vs-boosting">vs. Boosting<a class="headerlink" href="#vs-boosting" title="Permanent link">&para;</a></h3>
<p><strong>Boosting</strong>: Sequential training with re-weighting
- Requires training base models sequentially
- Not applicable to pre-trained heterogeneous ensembles
- Our method: works with <strong>any pre-trained base models</strong></p>
<hr />
<h2 id="13-theoretical-intuition-why-low-rank-helps">13. Theoretical Intuition: Why Low-Rank Helps<a class="headerlink" href="#13-theoretical-intuition-why-low-rank-helps" title="Permanent link">&para;</a></h2>
<h3 id="the-low-rank-prior">The Low-Rank Prior<a class="headerlink" href="#the-low-rank-prior" title="Permanent link">&para;</a></h3>
<p>By using <span class="arithmatex">\(d \ll \min(m, n)\)</span> latent dimensions, we enforce:</p>
<div class="arithmatex">\[\text{rank}(\hat{R}) \leq d\]</div>
<p>This <strong>low-rank constraint acts as regularization</strong>:
- Separates signal (low-rank patterns) from noise (high-rank residuals)
- Encourages generalization to similar points
- Learns shared structure across classifiers</p>
<h3 id="what-the-latent-factors-capture">What the Latent Factors Capture<a class="headerlink" href="#what-the-latent-factors-capture" title="Permanent link">&para;</a></h3>
<p><strong>Classifier factors <span class="arithmatex">\(x_u\)</span></strong> encode:
- Which types of patterns classifier <span class="arithmatex">\(u\)</span> is good at
- Its systematic biases (overfitting tendencies)
- Its complementarity with other classifiers</p>
<p><strong>Instance factors <span class="arithmatex">\(y_i\)</span></strong> encode:
- What "type" of point <span class="arithmatex">\(i\)</span> is (easy, hard, ambiguous)
- Which classifiers are likely reliable for this point
- Its position in the difficulty landscape</p>
<p>The dot product <span class="arithmatex">\(x_u^\top y_i\)</span> measures <strong>compatibility</strong>: how reliable is classifier <span class="arithmatex">\(u\)</span> for point <span class="arithmatex">\(i\)</span>?</p>
<hr />
<h2 id="14-advanced-variants-and-extensions">14. Advanced Variants and Extensions<a class="headerlink" href="#14-advanced-variants-and-extensions" title="Permanent link">&para;</a></h2>
<h3 id="alternative-reconstruction-losses">Alternative Reconstruction Losses<a class="headerlink" href="#alternative-reconstruction-losses" title="Permanent link">&para;</a></h3>
<p>Instead of squared error, use <strong>Bernoulli log-likelihood</strong> (since <span class="arithmatex">\(r_{ui} \in [0,1]\)</span>):</p>
<div class="arithmatex">\[L_{\text{recon}} = -\sum_{u,i} c_{ui} \left[ r_{ui} \log \hat{r}_{ui} + (1-r_{ui}) \log(1-\hat{r}_{ui}) \right]\]</div>
<p>This often produces <strong>sharper</strong> distinctions (less averaging).</p>
<h3 id="incorporating-additional-features">Incorporating Additional Features<a class="headerlink" href="#incorporating-additional-features" title="Permanent link">&para;</a></h3>
<p>Extend latent factors with side information:
$<span class="arithmatex">\(\hat{r}_{ui} = x_u^\top y_i + a_u^\top f_i + b_i\)</span>$</p>
<p>where <span class="arithmatex">\(f_i\)</span> are features of point <span class="arithmatex">\(i\)</span> (e.g., input features, metadata).</p>
<h3 id="hierarchical-structures">Hierarchical Structures<a class="headerlink" href="#hierarchical-structures" title="Permanent link">&para;</a></h3>
<p>Group similar classifiers and learn group-level factors:
$<span class="arithmatex">\(x_u = \beta_u x_{\text{group}(u)} + \epsilon_u\)</span>$</p>
<p>Encourages parameter sharing and handles large ensembles better.</p>
<h3 id="attention-mechanisms">Attention Mechanisms<a class="headerlink" href="#attention-mechanisms" title="Permanent link">&para;</a></h3>
<p>Replace dot product with learned attention:
$<span class="arithmatex">\(\hat{r}_{ui} = \text{Attention}(x_u, y_i) = \text{softmax}(x_u^\top W y_i)\)</span>$</p>
<p>Allows more flexible interactions.</p>
<hr />
<h2 id="15-practical-implementation-guide">15. Practical Implementation Guide<a class="headerlink" href="#15-practical-implementation-guide" title="Permanent link">&para;</a></h2>
<h3 id="hyperparameters">Hyperparameters<a class="headerlink" href="#hyperparameters" title="Permanent link">&para;</a></h3>
<ol>
<li><strong>Latent dimension <span class="arithmatex">\(d\)</span></strong>: Start with <span class="arithmatex">\(d \in [10, 50]\)</span></li>
<li>Too small: underfitting</li>
<li>Too large: overfitting</li>
<li>
<p>Rule of thumb: <span class="arithmatex">\(d \approx \sqrt{m}\)</span> or cross-validate</p>
</li>
<li>
<p><strong>Regularization <span class="arithmatex">\(\lambda\)</span></strong>: Start with <span class="arithmatex">\(\lambda \in [0.01, 0.1]\)</span></p>
</li>
<li>Adjust based on training set size</li>
<li>
<p>Higher <span class="arithmatex">\(\lambda\)</span> for smaller datasets</p>
</li>
<li>
<p><strong>Trade-off <span class="arithmatex">\(\rho\)</span></strong>: Start with <span class="arithmatex">\(\rho = 0.5\)</span></p>
</li>
<li>Increase if base models are reliable</li>
<li>
<p>Decrease if labels are noisy</p>
</li>
<li>
<p><strong>Temperature</strong> (if using Bernoulli loss): Start with <span class="arithmatex">\(T = 1\)</span></p>
</li>
<li>Similar to KD, can soften distributions</li>
</ol>
<h3 id="validation-strategy">Validation Strategy<a class="headerlink" href="#validation-strategy" title="Permanent link">&para;</a></h3>
<p>Use cross-validation on the labeled set <span class="arithmatex">\(\mathcal{L}\)</span>:
- Split <span class="arithmatex">\(\mathcal{L}\)</span> into train/validation
- Train on <span class="arithmatex">\(\mathcal{L}_{\text{train}} \cup \mathcal{U}\)</span> (transductive)
- Validate on <span class="arithmatex">\(\mathcal{L}_{\text{val}}\)</span>
- Select hyperparameters maximizing validation performance</p>
<h3 id="computational-considerations">Computational Considerations<a class="headerlink" href="#computational-considerations" title="Permanent link">&para;</a></h3>
<p><strong>Memory</strong>: Store <span class="arithmatex">\(X \in \mathbb{R}^{d \times m}\)</span>, <span class="arithmatex">\(Y \in \mathbb{R}^{d \times n}\)</span>
- Total: <span class="arithmatex">\(O(d(m+n))\)</span> space
- Much smaller than full <span class="arithmatex">\(R\)</span> if <span class="arithmatex">\(d \ll \min(m,n)\)</span></p>
<p><strong>Time per iteration</strong>:
- ALS update: <span class="arithmatex">\(O(d^2(m+n) + d^3(m+n))\)</span>
- Aggregator update: <span class="arithmatex">\(O(|\mathcal{L}| \cdot m)\)</span>
- Typical: seconds to minutes for moderate-sized problems</p>
<hr />
<h2 id="16-diagnostic-tools-and-debugging">16. Diagnostic Tools and Debugging<a class="headerlink" href="#16-diagnostic-tools-and-debugging" title="Permanent link">&para;</a></h2>
<h3 id="check-reconstruction-quality">Check Reconstruction Quality<a class="headerlink" href="#check-reconstruction-quality" title="Permanent link">&para;</a></h3>
<p>Monitor reconstruction error separately on train/test:
$<span class="arithmatex">\(\text{RMSE}_{\mathcal{L}} = \sqrt{\frac{1}{m|\mathcal{L}|}\sum_{u,i \in \mathcal{L}} (r_{ui} - \hat{r}_{ui})^2}\)</span>$</p>
<div class="arithmatex">\[\text{RMSE}_{\mathcal{U}} = \sqrt{\frac{1}{m|\mathcal{U}|}\sum_{u,i \in \mathcal{U}} (r_{ui} - \hat{r}_{ui})^2}\]</div>
<p>Large gap suggests overfitting to labeled structure.</p>
<h3 id="visualize-latent-spaces">Visualize Latent Spaces<a class="headerlink" href="#visualize-latent-spaces" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>t-SNE/UMAP of <span class="arithmatex">\(Y\)</span></strong>: Do labeled points cluster by class?</li>
<li><strong>Classifier similarities</strong>: <span class="arithmatex">\(\text{sim}(x_u, x_v) = \frac{x_u^\top x_v}{\|x_u\|\|x_v\|}\)</span></li>
<li><strong>Point difficulties</strong>: <span class="arithmatex">\(\|y_i\|\)</span> (higher norm  more unusual)</li>
</ul>
<h3 id="analyze-learned-weights">Analyze Learned Weights<a class="headerlink" href="#analyze-learned-weights" title="Permanent link">&para;</a></h3>
<p>For weighted aggregation, examine learned <span class="arithmatex">\(w\)</span>:
- Which classifiers get highest weight?
- Does this match expected reliability?
- Are weights interpretable?</p>
<hr />
<h2 id="17-when-will-this-work-vs-stacking">17. When Will This Work vs. Stacking?<a class="headerlink" href="#17-when-will-this-work-vs-stacking" title="Permanent link">&para;</a></h2>
<h3 id="cf-ensemble-advantages">CF-Ensemble Advantages<a class="headerlink" href="#cf-ensemble-advantages" title="Permanent link">&para;</a></h3>
<p><strong>Works better when</strong>:
- Base models have <strong>complementary errors</strong> (different failure modes)
- Large unlabeled test set with structure (benefits from transduction)
- Base models are <strong>diverse</strong> (different architectures, features)
- Moderate labeled data (regularization via reconstruction helps)</p>
<p><strong>Example</strong>: Medical diagnosis with multiple modalities (imaging, labs, clinical notes) where each model excels in different patient subgroups.</p>
<h3 id="stacking-advantages">Stacking Advantages<a class="headerlink" href="#stacking-advantages" title="Permanent link">&para;</a></h3>
<p><strong>Works better when</strong>:
- Very large labeled training set
- Base models are highly reliable and well-calibrated
- Test distribution differs significantly from train (distribution shift)
- Need strict inductive guarantees</p>
<p><strong>Example</strong>: Standard benchmark tasks with abundant labeled data.</p>
<h3 id="best-of-both-worlds">Best of Both Worlds<a class="headerlink" href="#best-of-both-worlds" title="Permanent link">&para;</a></h3>
<p>Hybrid approach:
1. Use CF-ensemble for transductive test set
2. Train stacker as backup for out-of-distribution points
3. Detect distribution shift and route accordingly</p>
<hr />
<h2 id="18-mathematical-summary">18. Mathematical Summary<a class="headerlink" href="#18-mathematical-summary" title="Permanent link">&para;</a></h2>
<h3 id="complete-formulation">Complete Formulation<a class="headerlink" href="#complete-formulation" title="Permanent link">&para;</a></h3>
<p><strong>Given</strong>:
- Probability matrix <span class="arithmatex">\(R \in [0,1]^{m \times n}\)</span>
- Confidence matrix <span class="arithmatex">\(C \in \mathbb{R}_+^{m \times n}\)</span>
- Labels <span class="arithmatex">\(\{y_i\}_{i \in \mathcal{L}}\)</span> for labeled set <span class="arithmatex">\(\mathcal{L} \subset \{1,\ldots,n\}\)</span></p>
<p><strong>Optimize</strong>:
$<span class="arithmatex">\(\min_{X \in \mathbb{R}^{d \times m}, Y \in \mathbb{R}^{d \times n}, \theta} \mathcal{L}_{\text{CF-Ensemble}}(X, Y, \theta)\)</span>$</p>
<p>where:
$<span class="arithmatex">\(\begin{align}
\mathcal{L}_{\text{CF-Ensemble}} &amp;= \rho \left[ \sum_{u=1}^m \sum_{i=1}^n c_{ui}(r_{ui} - x_u^\top y_i)^2 + \lambda(\|X\|_F^2 + \|Y\|_F^2) \right] \\
&amp;\quad + (1-\rho) \sum_{i \in \mathcal{L}} \left[ -y_i \log g_\theta(\hat{r}_{\cdot i}) - (1-y_i) \log(1-g_\theta(\hat{r}_{\cdot i})) \right]
\end{align}\)</span>$</p>
<p><strong>Prediction</strong>:
For point <span class="arithmatex">\(i\)</span> (train or test):
$<span class="arithmatex">\(\hat{p}_i = g_\theta(\hat{r}_{\cdot i}) \quad \text{where} \quad \hat{r}_{ui} = x_u^\top y_i\)</span>$</p>
<hr />
<h2 id="19-philosophical-perspective">19. Philosophical Perspective<a class="headerlink" href="#19-philosophical-perspective" title="Permanent link">&para;</a></h2>
<h3 id="learning-from-behavior-not-just-labels">Learning from Behavior, Not Just Labels<a class="headerlink" href="#learning-from-behavior-not-just-labels" title="Permanent link">&para;</a></h3>
<p>Like knowledge distillation, CF-ensemble embodies a key principle:</p>
<blockquote>
<p><strong>Models learn more from <em>how</em> other models think than from <em>what</em> the correct answer is.</strong></p>
</blockquote>
<p>The probability matrix <span class="arithmatex">\(R\)</span> encodes:
- Patterns of agreement and disagreement
- Regions of confidence and uncertainty
- Complementary expertise across models</p>
<p>By factorizing <span class="arithmatex">\(R\)</span> while supervising on labels, we:
- Discover latent structure in ensemble behavior
- Learn which patterns are signal vs noise
- Build predictions that <strong>transcend individual model limitations</strong></p>
<h3 id="from-compression-to-composition">From Compression to Composition<a class="headerlink" href="#from-compression-to-composition" title="Permanent link">&para;</a></h3>
<p>KD compresses a single model; CF-ensemble <strong>composes multiple models</strong>:
- Each base model contributes partial knowledge
- Latent factors discover how to combine them
- The result can exceed any individual model</p>
<p>This is ensemble learning in its purest form: <strong>the whole is greater than the sum of parts</strong>.</p>
<hr />
<h2 id="20-research-directions-and-open-questions">20. Research Directions and Open Questions<a class="headerlink" href="#20-research-directions-and-open-questions" title="Permanent link">&para;</a></h2>
<h3 id="theoretical-questions">Theoretical Questions<a class="headerlink" href="#theoretical-questions" title="Permanent link">&para;</a></h3>
<ol>
<li><strong>Generalization bounds</strong>: How does transductive access affect generalization?</li>
<li><strong>Sample complexity</strong>: How many labeled examples are needed for reliable latent factors?</li>
<li><strong>Identifiability</strong>: Are learned factors unique (up to rotation)?</li>
</ol>
<h3 id="algorithmic-improvements">Algorithmic Improvements<a class="headerlink" href="#algorithmic-improvements" title="Permanent link">&para;</a></h3>
<ol>
<li><strong>Non-linear factorization</strong>: Replace <span class="arithmatex">\(x_u^\top y_i\)</span> with neural networks</li>
<li><strong>Dynamic ensembles</strong>: Update <span class="arithmatex">\(X\)</span> when new classifiers are added</li>
<li><strong>Active learning</strong>: Which points should we label to maximally improve <span class="arithmatex">\(Y\)</span>?</li>
</ol>
<h3 id="applications">Applications<a class="headerlink" href="#applications" title="Permanent link">&para;</a></h3>
<ol>
<li><strong>Deep ensembles</strong>: Apply to neural network ensembles with thousands of models</li>
<li><strong>Multi-task learning</strong>: Share latent factors across related tasks</li>
<li><strong>Federated learning</strong>: Learn <span class="arithmatex">\(X\)</span> without sharing raw predictions</li>
</ol>
<hr />
<h2 id="21-conclusion">21. Conclusion<a class="headerlink" href="#21-conclusion" title="Permanent link">&para;</a></h2>
<p>We've developed a unified framework connecting knowledge distillation and collaborative filtering for ensemble learning. The key insights are:</p>
<ol>
<li>
<p><strong>Structural analogy</strong>: KD's soft-hard combination maps directly to CF-ensemble's reconstruction-supervision combination</p>
</li>
<li>
<p><strong>Mathematical formulation</strong>: The loss <span class="arithmatex">\(\mathcal{L} = \rho \cdot L_{\text{recon}} + (1-\rho) \cdot L_{\text{sup}}\)</span> balances matrix fidelity with predictive accuracy</p>
</li>
<li>
<p><strong>Practical advantages</strong>: Leverages unlabeled test structure, learns instance-specific weights, and regularizes through low-rank factorization</p>
</li>
<li>
<p><strong>Why it should work</strong>: Unlike pure reconstruction, adding supervision teaches the model to distinguish signal from noise</p>
</li>
</ol>
<p>This framework addresses the fundamental limitation of previous CF-ensemble approaches: <strong>faithfully reconstructing the probability matrix isn't enoughwe must reconstruct it in a way that aligns with true labels</strong>.</p>
<hr />
<h2 id="references">References<a class="headerlink" href="#references" title="Permanent link">&para;</a></h2>
<ol>
<li>Koren, Y., Bell, R., &amp; Volinsky, C. (2009). <em>Matrix Factorization Techniques for Recommender Systems</em>. IEEE Computer.</li>
<li>Hinton, G., et al. (2015). <em>Distilling the Knowledge in a Neural Network</em>. NIPS Workshop.</li>
<li>Hu, Y., Koren, Y., &amp; Volinsky, C. (2008). <em>Collaborative Filtering for Implicit Feedback Datasets</em>. ICDM.</li>
</ol>
<hr />
<p><strong>Next Steps</strong>: Implement this framework and empirically test whether the KD-inspired combined objective finally makes CF-ensemble learning work! See the implementation guide in <code>notebooks/</code> and source code in <code>src/cfensemble/</code>.</p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2026 CF-Ensemble Research Team
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        
<div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://github.com/pleiadian53/cf-ensemble" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      
      <script id="__config" type="application/json">{"annotate": null, "base": "../..", "features": ["navigation.instant", "navigation.tracking", "navigation.tabs", "navigation.tabs.sticky", "navigation.sections", "navigation.expand", "navigation.top", "search.suggest", "search.highlight", "content.code.copy", "content.action.edit"], "search": "../../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": {"provider": "mike"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.79ae519e.min.js"></script>
      
        <script src="../../javascripts/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>